% Seizure prediction 
% Author  : Srinath Narayanan
% For ECE 251B course at UCSD
% Date : 06-11-2017

function [y_est,w_P_est] = myparticle(x_inp1,y,w_int)

    %% Data Block
    % data=importdata('../Data/Data_N_Ind2261.txt');
    % datax=data(:,1);
    % p=10;
    % w_int=KR_trainer(p);

    c=0.0001;

    %% initialize the variables
    % set(0,'DefaultFigureWindowStyle','docked') %dock the figures..just a personal preference you don't need this.
    % x_R = 1; % Noise covariance in the measurement 
    % T = numel(datax); % duration the chase (i.e. number of iterations).

    x_N = 1; % Noise covariance in the system (i.e. process noise in the state update, here, we'll use a gaussian.)
    N = 1000; % The number of particles the system generates. The larger this is, the better your approximation, but the more computation you need.

    %initilize our initial, prior particle distribution as a gaussian around
    %the true initial value

    V = 2; %define the variance of the initial esimate
    w_P = []; % define the vector of particles
    p=numel(w_int);
    x_inp=x_inp1';

    % make the randomly generated particles from the initial prior gaussian distribution
    for i = 1:N
        w_P(i,:) = w_int + sqrt(V)*randn(1,p);
    end

    % Including the kf_trainer output as well, to yield some robustness.
    w_P(1,:)=w_int;


    % Measurement - We can update x_inp and y as we slide the window.
    % x_inp = flipud(datax(1:p));
    % y=datax(p+1);

    %generate the observations from the randomly selected particles, based upon
    %the given function
    y_est = []; % time by time output of the particle filters estimate
    % y_est_out = [w_int*x_inp]; % the vector of particle filter estimates.
    % w_P_est_array=[w_int];

    err=Inf;
    iter=1;
    P_w_old=rand(1,N);
    P_w_old=P_w_old/sum(P_w_old);

    % iter<100 && 
    while(err>0.1)
        iter=iter+1;

        %Here, we do the particle filter
        for i = 1:N
            %given the prior set of particle, run each of these particles through the state
            %update model to make a new set of transitioned predictions. 

    %         x_P_update(i)
            xtemp=[w_P(i,:)*x_inp]; %+ sqrt(x_N) * randn();

            %with these new updated particle weights, update the observations
            %for each of these particles.
    %         z_update(i) = x_P_update(i);

            %Generate the weights for each of these particles.
            %The weights are based upon the probability of the given
            %observation for a particle, GIVEN the actual observation.
            %That is, if we observe a location z, and we know our observation error is
            %guassian with variance x_R, then the probability of seeing a given
            %z centered at that actual measurement is (from the equation of a
            %gaussian)

            % Gaussian does not work - since it sends prob -> 0, and sum(p)=0,
            % and leads to some undersirable non-convergent errors.
            % Theoritically it should work though.
    %         P_w(i) = (1/sqrt(2*pi*x_R)) * exp(-(y - z_update(i)).^2./(2*x_R));


            % To Guarentee convergence, I just use the inverse of the
            % euclidean norm, which is again symmentric but has a sharper tail.

            P_w(i)=1/(norm(y - xtemp,2)^2+c);
        end

        %     disp(P_w);

        % If the particles are way off what our measurement was, the
        % probability will be zero. Hence, we have to deal with the NaN case,
        % where it is then uniformly distributed.
        % Normalize to form a probability distribution (i.e. sum to 1).
        pw1=P_w;
        if(sum(P_w)==0)
    %         disp('once');
            P_w=P_w_old;
            %% Or, we could normalize it, or randomize it. If using gaussian, this was the problem.
            %         P_w=1/N*ones(1,N);
            %           temp=randn(1,N);
            %           P_w=temp/sum(temp);
        else
            P_w = P_w/sum(P_w);
        end

        %% Resampling: From this new distribution, now we randomly sample from it to generate our new estimate particles

        %what this code specifically does is randomly, uniformally, sample from
        %the cummulative distribution of the probability distribution
        %generated by the weighted vector P_w.  If you sample randomly over
        %this distribution, you will select values based upon there statistical
        %probability, and thus, on average, pick values with the higher weights
        %(i.e. high probability of being correct given the observation z).
        %store this new value to the new estimate which will go back into the
        %next iteration
    %     disp(size(w_P));
        for i = 1 : N
    %         disp(i);
    %         disp(temp);
            try
                w_P(i,:)=w_P(find(rand<= cumsum(P_w),1),:);
            catch
                disp("ERROR");
                disp("pw:");
                disp(P_w);
    %             disp("random");
    %             disp(r);
                disp("PW1:");
                disp(pw1);
    %             disp("BOOL:");
    %             disp(bool);
    %             disp(temp);
    %             disp(i);
                pause;
            end
        end
        P_w_old=P_w;
        %The final estimate is some metric of these final resampling, such as
        %the mean value or variance

        w_P_est=mean(w_P);      % Median might yield faster convergence.

        for i = 1:N
            w_P(i,:) = w_P_est + sqrt(V)*randn(1,p);
        end

        % Save data in arrays for later plotting

    %     w_P_est_array=[w_P_est_array;w_P_est];
        y_est=w_P_est*x_inp;
    %     y_est_out = [y_est_out y_est];
        err=abs(y_est-y);
    end

    % disp(iter);
end

%% Code for visualization

% disp('The w by training kalman on the dataset');
% disp(trainer0001(p));
% disp('The w by training particle filter on the dataset');
% % disp(w_P_est);
% 
% figure;
% clf;
% plot(y_est_out,'r');
% hold on;
% plot(1:numel(y_est_out),ones(1,numel(y_est_out))*y,'b');
% hold off;
% legend('Varying y/_estimated, due to changing w by particle filtering','p+1 value','Location','best');
% title('Particle filtering');